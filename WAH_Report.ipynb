{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAH Report Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date, datetime\n",
    "import warnings\n",
    "from shutil import copy\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import win32com.client\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from win32com.client import constants\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring fiscal month calculator functions\n",
    "def isleap(year):\n",
    "    # Return True for leap years, False for non-leap years.\n",
    "    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "\n",
    "# takes in a date, and decides which fiscal month it is.\n",
    "def decide_fm(date):\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = 1\n",
    "\n",
    "    if (month == 12) and (date.day > 28):\n",
    "        year = date.year + 1\n",
    "        month = 1\n",
    "    elif date.day > 28:\n",
    "        month = date.month + 1\n",
    "\n",
    "    date = date.replace(year=year, month=month, day=day)\n",
    "    return date\n",
    "\n",
    "# takes in a date and decides what the beginning day of the fiscal month is\n",
    "def decide_fm_beginning(date):\n",
    "    year = date.year\n",
    "    month = (date + relativedelta(months=-1)).month\n",
    "    day = 29\n",
    "\n",
    "    if date.month == 1:\n",
    "        year = year - 1\n",
    "    elif (isleap(date.year) == False) and (date.month == 3):\n",
    "        month = date.month\n",
    "        day = 1\n",
    "\n",
    "    date = date.replace(year=year, month=month, day=day)\n",
    "    return date\n",
    "\n",
    "# takes in a date and decides what the end of the fiscal month is\n",
    "def decide_fm_end(date):\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = 28\n",
    "\n",
    "    if (month == 12) and (date.day > 28):\n",
    "        year = date.year + 1\n",
    "        month = 1\n",
    "    elif date.day > 28:\n",
    "        month = date.month + 1\n",
    "\n",
    "    date = date.replace(year=year, month=month, day=day)\n",
    "    return date\n",
    "\n",
    "# function in order to calculate if the agent currently works weekends based on the days worked string\n",
    "def calc_weekend_work(shift):\n",
    "    if isinstance(shift, float):\n",
    "        return np.nan\n",
    "    elif ('Y' in shift) or ('S' in shift):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "today = date(2023,3,15)\n",
    "last_month = today + relativedelta(months=-1)\n",
    "last_fiscal = decide_fm(last_month)\n",
    "fiscal_beginning = decide_fm_beginning(last_fiscal)\n",
    "fiscal_end = decide_fm_end(last_fiscal)\n",
    "lookback_beginning = decide_fm_beginning(last_fiscal + relativedelta(months=-2))\n",
    "lookback_end = decide_fm_end(last_fiscal)\n",
    "wah_date = date(2022,8,1)\n",
    "required_ot = 4\n",
    "final_shrink_date = lookback_end + relativedelta(days=14)\n",
    "print(final_shrink_date)\n",
    "print(f'Running the WAH Eligibility report for {last_fiscal.strftime(\"%m/%d/%Y\")}')\n",
    "if today < final_shrink_date:\n",
    "    print(f'Shrink data has not finalized and will not until {final_shrink_date.strftime(\"%m/%d/%Y\")}')\n",
    "    print('Please try again running the report on or after that date.')\n",
    "    sleep(60)\n",
    "    exit()\n",
    "ot_fiscal = date(2023,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(last_fiscal.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_lookback_month = last_fiscal + relativedelta(months=-1)\n",
    "last_lookback_beginning = decide_fm_beginning(last_lookback_month + relativedelta(months=-2))\n",
    "last_lookback_end = decide_fm_end(last_lookback_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declares working paths\n",
    "cwd = os.getcwd()\n",
    "query_folder = os.path.join(cwd, 'Queries')\n",
    "ot_query_name = 'Overtime_Query_Fiscal.sql'\n",
    "shrink_query_name = 'Shrink_Query.sql'\n",
    "roster_query_name = 'VR_Roster_Query.sql'\n",
    "ot_query_path = os.path.join(query_folder, ot_query_name)\n",
    "shrink_query_path = os.path.join(query_folder, shrink_query_name)\n",
    "roster_query_path = os.path.join(query_folder, roster_query_name)\n",
    "\n",
    "\n",
    "data_folder = os.path.join(cwd, 'Data')\n",
    "if os.path.exists(data_folder) == False:\n",
    "    os.makedirs(data_folder)\n",
    "data_file = 'WAH Data.xlsx'\n",
    "data_path = os.path.join(data_folder, data_file)\n",
    "performance_file = 'Percentile_ranks.xlsx'\n",
    "performance_path = os.path.join(data_folder, performance_file)\n",
    "\n",
    "data_files = os.listdir(data_folder)\n",
    "ca_files = [value for value in data_files if value.startswith('CA') and value.endswith('xlsx')]\n",
    "ca_paths = [os.path.join(data_folder, basename) for basename in ca_files]\n",
    "ca_path = max(ca_paths, key=os.path.getctime)\n",
    "print(f'Latest Path for CAs:{ca_path}')\n",
    "print(os.path.getctime(ca_path))\n",
    "\n",
    "template_file = 'WAH_Eligibility_StatusCheck_Template.xlsx'\n",
    "template_folder = os.path.join(cwd, 'Templates')\n",
    "template_path = os.path.join(template_folder, template_file)\n",
    "\n",
    "reports_folder = os.path.join(cwd, 'Reports')\n",
    "reports_folder = cwd\n",
    "server_folder = r'' # Network Share drive\n",
    "server_folder = cwd\n",
    "save_name = f'WAH_Eligibility_StatusCheck_{fiscal_end.strftime(\"%m%d%y\")}.xlsx'\n",
    "save_path = os.path.join(reports_folder, save_name)\n",
    "server_path = os.path.join(server_folder, save_name)\n",
    "src_folder = os.path.join(cwd, 'src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries and Server connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in each of the sql queries from the queries folder\n",
    "with open(ot_query_path, 'r') as query:\n",
    "    ot_query = query.read()\n",
    "with open(shrink_query_path, 'r') as query:\n",
    "    shrink_query = query.read()\n",
    "with open(roster_query_path, 'r') as query:\n",
    "    roster_query = query.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection string to access server and creating the server connection\n",
    "conn_str = (\"Driver={SQL Server};\"\n",
    "            \"Server=;\" # Network Server Address\n",
    "            \"Database=Aspect;\"\n",
    "            \"Trusted_Connection=yes;\")\n",
    "\n",
    "# creating connection to server\n",
    "conn = pyodbc.connect(conn_str)\n",
    "print('Connecting to Server')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Source Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the source dataframes\n",
    "# Reading the roster dataframe from the server\n",
    "print('Retrieving Roster')\n",
    "roster_df = pd.read_sql(roster_query, conn)\n",
    "print('Roster Dataframe Created')\n",
    "print('-'*25)\n",
    "# correcting roster dataframe\n",
    "roster_df = roster_df.loc[roster_df['TERMINATEDDATE'].isna()]\n",
    "roster_df['NETIQWORKERID'] = roster_df['NETIQWORKERID'].astype(int).astype(str)\n",
    "roster_df['HIREDATE'] = pd.to_datetime(roster_df['HIREDATE']).dt.date\n",
    "roster_df['WP Start Date'] = pd.to_datetime(roster_df['WP Start Date']).dt.date\n",
    "\n",
    "# splitting the location into centers as well as correcting for Gran Vista\n",
    "for index, row in roster_df.iterrows():\n",
    "    call_center = row['MGMTAREANAME']\n",
    "    location = row['WorkLocation']\n",
    "    city = ' '.join(location.split(' ')[1:])\n",
    "    state = location.split(' ')[0]\n",
    "\n",
    "    updated_location = f'{city} {state}'\n",
    "    if 'Gran Vista' in call_center:\n",
    "        updated_location = f'{updated_location} (Gran Vista)'\n",
    "    roster_df.loc[index, 'MGMTAREANAME'] = updated_location\n",
    "\n",
    "# dropping columns in this way if another is accidentially added, it wont break script\n",
    "columns_to_keep = ['BossName',\n",
    "                   'BossBossName',\n",
    "                   'EmpName',\n",
    "                   'EmpTitle',\n",
    "                   'MGMTAREANAME',\n",
    "                   'NETIQWORKERID',\n",
    "                   'HIREDATE',\n",
    "                   'Days Worked',\n",
    "                   'Start/Stop',\n",
    "                   'WorkPlace',\n",
    "                   'WP Start Date']\n",
    "drop_columns = [value for value in roster_df.columns if value not in columns_to_keep]\n",
    "roster_df = roster_df.drop(columns=drop_columns)\n",
    "\n",
    "# reading the percentile dataframe and correcting types\n",
    "print('Retrieving Percentile Data')\n",
    "percentile_df = pd.read_excel(performance_path, engine='openpyxl')\n",
    "print('Percentile Data Loaded')\n",
    "print('-'*25)\n",
    "percentile_df['Fiscal Month'] = pd.to_datetime(percentile_df['Fiscal Month']).dt.date\n",
    "percentile_df['PSID'] = percentile_df['PSID'].astype(str)\n",
    "percentile_df['Overall Rank'] = percentile_df['Overall Rank'].astype(float)\n",
    "\n",
    "# checking for the latest fiscal month and ensuring that it is in the dataset before moving forward\n",
    "max_date = percentile_df['Fiscal Month'].max()\n",
    "if max_date != last_fiscal:\n",
    "    print(\"It looks like we do not have last month's data added in the Percentile Ranks. Please correct that by grabbing the lastest rankings from the ranking email and run again.\")\n",
    "    sleep(30)\n",
    "    exit()\n",
    "\n",
    "# Reading in the CA dataframe and correcting datatypes\n",
    "print('Retrieving Corrective Action Data')\n",
    "ca_df = pd.read_excel(ca_path, dtype=object)\n",
    "print('Corrective Action Data Loaded')\n",
    "print('-'*25)\n",
    "date_list = ['Effective Date (Occurence Dt.)',\n",
    "             'Purge Date',\n",
    "             'Term Date']\n",
    "for column in date_list:\n",
    "    ca_df[column] = pd.to_datetime(ca_df[column]).dt.date\n",
    "\n",
    "# reading in overtime dataframe\n",
    "print('Retrieving Overtime Data')\n",
    "overtime_df = pd.read_sql(ot_query, conn)\n",
    "print('Ovetime Data loaded')\n",
    "print('-'*25)\n",
    "\n",
    "overtime_df['PSID'] = overtime_df['PSID'].astype(int).astype(str)\n",
    "overtime_df['FiscalMonth'] = pd.to_datetime(overtime_df['FiscalMonth']).dt.date\n",
    "\n",
    "# reading in the shrink dataframe and correcting datatypes\n",
    "print('Retrieving shrink data')\n",
    "shrink_df = pd.read_sql(shrink_query, conn)\n",
    "print('Shrink Data loaded')\n",
    "print('-'*25)\n",
    "shrink_df['FiscalMonth'] = pd.to_datetime(shrink_df['FiscalMonth']).dt.date\n",
    "shrink_df['EmpID'] = shrink_df['EmpID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrink_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Prior Month WAH eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the prior percentile dataframe and calculating those who passed threshold\n",
    "print('-'*25)\n",
    "print('Calculating prior month')\n",
    "prior_percentile_df = percentile_df.loc[percentile_df['Fiscal Month'].between(last_lookback_beginning, last_lookback_end)].groupby('PSID').agg({\n",
    "    'Overall Rank':'mean'\n",
    "}).reset_index()\n",
    "prior_percentile_df['Over 50'] = prior_percentile_df['Overall Rank'].map(lambda x: True if x >= 50 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of psid's that have a corrective during the prior lookback period\n",
    "prior_ca_list = ca_df.loc[ca_df['Effective Date (Occurence Dt.)'].between(last_lookback_beginning, last_lookback_end)]['PSID'].tolist()\n",
    "prior_ca_list = [str(value) for value in prior_ca_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the prior OT Dataframe and mapping those who are over the required OT\n",
    "prior_ot_df = overtime_df.loc[overtime_df['FiscalMonth'] == last_lookback_month]\n",
    "prior_ot_df['OT Met'] = prior_ot_df['OT Total'].map(lambda x: True if x > required_ot else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the prior shrink dataframe and creating columns to see who \n",
    "prior_shrink_df = shrink_df.loc[shrink_df['FiscalMonth'].between(last_lookback_beginning, last_lookback_end)].groupby('EmpID').agg({\n",
    "    'Unplanned OOO': 'sum',\n",
    "    'Scheduled': 'sum'\n",
    "}).reset_index()\n",
    "prior_shrink_df['Shrinkage'] = prior_shrink_df['Unplanned OOO'] / prior_shrink_df['Scheduled']\n",
    "prior_shrink_df['Shrink Pass'] = prior_shrink_df['Shrinkage'].map(lambda x: True if x <=.07 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the WAH Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the roster dataframe in order to create a more readable wah export\n",
    "roster_rename_dict = {'BossName': 'Supervisor',\n",
    "                      'BossBossName': 'Manager',\n",
    "                      'EmpName': 'Agent',\n",
    "                      'EmpTitle': 'Title',\n",
    "                      'NETIQWORKERID': 'PSID',\n",
    "                      'MGMTAREANAME': 'Call Center'}\n",
    "wah_df = roster_df.rename(columns=roster_rename_dict)\n",
    "# filtering for just reps\n",
    "wah_df = wah_df.loc[wah_df['Title'].str.contains('Rep ')]\n",
    "wah_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating columns for wah and if they were prior to the cutoff date \n",
    "wah_df['Remote'] = wah_df['WorkPlace'].map(lambda x: x if (x == None) else True if (x.startswith('WAH')) else False)\n",
    "wah_df['WAH Prior'] = wah_df['WP Start Date'].map(lambda x: x if (x == None) else True if x <= wah_date else False)\n",
    "# correcting for the people who are not remote in order to not mark them eligible if they have been in center since before the cutoff date\n",
    "wah_df.loc[(wah_df['WAH Prior'] == True) & (wah_df['Remote']) == False, 'WAH Prior'] = False\n",
    "# parsing the Days Worked column to create a column of booleans if weekends are worked\n",
    "wah_df['Works_Weekend'] = wah_df['Days Worked'].map(lambda x: calc_weekend_work(x) if x != None else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging prior data with a cloned wah dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_wah_df = wah_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the prior wah with the created prior dataframes\n",
    "prior_wah_df = prior_wah_df.merge(prior_percentile_df.loc[:,['PSID', 'Over 50']], how='left', left_on='PSID',right_on='PSID')\n",
    "prior_wah_df = prior_wah_df.merge(prior_shrink_df.loc[:,['EmpID', 'Shrink Pass']], how='left', left_on='PSID', right_on='EmpID').drop(columns='EmpID')\n",
    "prior_wah_df['No CA'] = prior_wah_df['PSID'].map(lambda x: True if x not in prior_ca_list else False)\n",
    "prior_wah_df = prior_wah_df.merge(prior_ot_df.loc[:,['PSID', 'OT Met']], how='left', left_on='PSID', right_on='PSID')\n",
    "prior_wah_df.loc[prior_wah_df['Remote'] == False, 'OT Met'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping through the prior wah df in order to create a column if they passed the prior month in order to see if the \n",
    "# agent should come back in office or not\n",
    "for index, row in prior_wah_df.iterrows():\n",
    "    remote = row['Remote']\n",
    "    weekends = row['Works_Weekend']\n",
    "    performance = row['Over 50']\n",
    "    shrink = row['Shrink Pass']\n",
    "    ca = row['No CA']\n",
    "    ot = row['OT Met']\n",
    "    wah_prior = row['WAH Prior']\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # rather than creating nested if statements, appending results to a list to check the length of the list to see if agent passed\n",
    "    if (wah_prior == False) and (weekends == False):\n",
    "        results.append('Weekends')\n",
    "    if performance == False:\n",
    "        results.append('Performance')\n",
    "    if ca == False:\n",
    "        results.append('CA')\n",
    "    if shrink == False:\n",
    "        results.append('Shrink')\n",
    "    if (remote == True) and (ot == False) and (last_fiscal >= ot_fiscal):\n",
    "        results.append('OT')\n",
    "\n",
    "    if len(results) == 0:\n",
    "        prior_wah_df.loc[index, 'Pass Last FM'] = True\n",
    "    else:\n",
    "        prior_wah_df.loc[index, 'Pass Last FM'] = False\n",
    "else:\n",
    "    print('Prior month has concluded calculating')\n",
    "    print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_wah_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data used for this month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the results of the prior month onto the wah df\n",
    "print('-'*25)\n",
    "print('Calculating this month')\n",
    "wah_df = wah_df.merge(prior_wah_df.loc[:,['PSID', 'Pass Last FM']], how='left', on='PSID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe to calculate the number of scorecards inside of the percentile df exist for the agent\n",
    "data_df = percentile_df.loc[percentile_df['Overall Rank'].notna()]\n",
    "data_df = data_df.groupby('PSID').count()['Fiscal Month'].reset_index()\n",
    "data_df = data_df.rename(columns={'Fiscal Month': 'Months_of_Data'})\n",
    "# dropping unnecessary columns\n",
    "columns_to_keep = ['PSID', 'Months_of_Data']\n",
    "drop_columns = [value for value in data_df.columns if value not in columns_to_keep]\n",
    "data_df = data_df.drop(columns=drop_columns)\n",
    "\n",
    "# averaging the last 3 months of percentile data, and adding in how many months of data are possesed by the agent\n",
    "percentile_df = percentile_df.loc[percentile_df['Fiscal Month'] >= (last_fiscal + relativedelta(months=-2))].groupby('PSID').mean()['Overall Rank'].reset_index()\n",
    "percentile_df = percentile_df.merge(data_df, how='left', on='PSID')\n",
    "# creating a boolean column of agents who passed the 50% mark\n",
    "percentile_df['Over 50'] = percentile_df['Overall Rank'].map(lambda x: True if x >= 50 else False)\n",
    "\n",
    "# joining the new percentile_df onto the wah_df \n",
    "wah_df = wah_df.merge(percentile_df.loc[:,['PSID', 'Months_of_Data', 'Over 50']], how='inner', left_on='PSID', right_on='PSID')\n",
    "wah_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the ca dataframe for the last three fiscal months of ca's\n",
    "ca_df = ca_df.loc[ca_df['Effective Date (Occurence Dt.)'] >= lookback_beginning]\n",
    "\n",
    "# sending the unique ca values to a list and mapping that list to the wah_df to create a boolean column\n",
    "ca_list = ca_df['PSID'].unique().tolist()\n",
    "ca_list = [str(value) for value in ca_list]\n",
    "wah_df['No CA'] = wah_df['PSID'].map(lambda x: True if x not in ca_list else False)\n",
    "wah_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of individuals above OT cutoff and then creating a column from the results\n",
    "overtime_list = overtime_df.loc[overtime_df['OT Total'] >= required_ot, 'PSID'].unique().tolist()\n",
    "overtime_list = [str(value) for value in overtime_list]\n",
    "wah_df['Overtime Met'] = wah_df['PSID'].map(lambda x: True if x in overtime_list else False)\n",
    "wah_df.loc[wah_df['Remote'] == False, 'Overtime Met'] = np.nan\n",
    "wah_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the shrink dataframe and creating a column of people below the threshold.\n",
    "shrink_df = shrink_df.loc[shrink_df['FiscalMonth'] >= lookback_beginning].groupby('EmpID').agg({\n",
    "    'Unplanned OOO': 'sum',\n",
    "    'Scheduled':'sum'\n",
    "}).reset_index()\n",
    "shrink_df['Shrinkage'] = shrink_df['Unplanned OOO'] / shrink_df['Scheduled']\n",
    "shrink_df['Shrink Pass'] = shrink_df['Shrinkage'].map(lambda x: True if x <= .07 else False)\n",
    "# joining the shrink dataframe with the main wah_df for the Shrink Pass Column\n",
    "wah_df = wah_df.merge(shrink_df.loc[:,['EmpID', 'Shrink Pass']], how='left', left_on='PSID', right_on='EmpID').drop(columns='EmpID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column of people who have met the tenure requirement\n",
    "# either 3 scorecards or 6 months tenure. Both are below. Uncomment for one or the other\n",
    "# wah_df['Enough Data'] = wah_df['Months_of_Data'].map(lambda x: True if x >= 3 else False)\n",
    "wah_df['Enough Data'] = wah_df['HIREDATE'].map(lambda x: True if x <= (fiscal_beginning + relativedelta(months=-5)) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wah_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping through the df to find the people who fit the criteria in order to mark them eligible\n",
    "# if they are not eligible, or did not pass this month, create a reason string in order to explain why\n",
    "# also account for the people who have failed two months in a row vs only one month\n",
    "for index, row in wah_df.iterrows():\n",
    "    remote = row['Remote']\n",
    "    data_check = row['Enough Data']\n",
    "    weekends = row['Works_Weekend']\n",
    "    performance = row['Over 50']\n",
    "    ca = row['No CA']\n",
    "    shrink = row['Shrink Pass']\n",
    "    ot = row['Overtime Met']\n",
    "    last_fm = row['Pass Last FM']\n",
    "    wah_prior = row['WAH Prior']\n",
    "\n",
    "    results = []\n",
    "    if data_check == False:\n",
    "        results.append('Data')\n",
    "    if (wah_prior == False) and (weekends == False):\n",
    "        results.append('Weekends')\n",
    "    if performance == False:\n",
    "        results.append('Performance')\n",
    "    if ca == False:\n",
    "        results.append('CA')\n",
    "    if shrink == False:\n",
    "        results.append('Shrink')\n",
    "    if (remote) and (ot == False) and (last_fiscal >= ot_fiscal):\n",
    "        results.append('OT')\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        wah_df.loc[index, 'Pass This Month'] = True\n",
    "        wah_df.loc[index, 'WAH Eligible'] = 'Yes'\n",
    "    else:\n",
    "        wah_df.loc[index, 'Pass This Month'] = False\n",
    "\n",
    "        data_str = 'not having enough data yet'\n",
    "        weekend_str = 'not being scheduled for a weekend day'\n",
    "        performance_str = 'not meeting average performance'\n",
    "        ca_str = 'being on a Corrective Action'\n",
    "        shrink_str = 'too many unplanned absences'\n",
    "        ot_str = f'not working the required {required_ot} hours of overtime'\n",
    "\n",
    "        dictionary = {'Weekends': weekend_str,\n",
    "                      'Performance': performance_str,\n",
    "                      'CA': ca_str,\n",
    "                      'OT': ot_str,\n",
    "                      'Data': data_str,\n",
    "                      'Shrink': shrink_str}\n",
    "        reason = ''\n",
    "\n",
    "        # if the results are a certain length, the string will reference the dictionary to return the reason and build the sentence\n",
    "        if len(results) == 1:\n",
    "            reason = f'This agent did not pass this month due to {dictionary.get(results[0])}.'\n",
    "        elif len(results) == 2:\n",
    "            reason = f'This agent did not pass this month due to {dictionary.get(results[0])} and {dictionary.get(results[1])}.'\n",
    "        elif len(results) == 3:\n",
    "            reason = f'This agent did not pass this month due to {dictionary.get(results[0])}, {dictionary.get(results[1])}, and {dictionary.get(results[2])}.'\n",
    "        elif len(results) == 4:\n",
    "            reason = f'This agent did not pass this month due to {dictionary.get(results[0])}, {dictionary.get(results[1])}, {dictionary.get(results[2])}, and {dictionary.get(results[3])}.'\n",
    "        elif len(results) == 5:\n",
    "            reason = f'This agent did not pass this month due to {dictionary.get(results[0])}, {dictionary.get(results[1])}, {dictionary.get(results[2])}, {dictionary.get(results[3])}, and {dictionary.get(results[4])}.'\n",
    "        elif len(results) == 6:\n",
    "            reason = f'This agent did not pass this month due to {dictionary.get(results[0])}, {dictionary.get(results[1])}, {dictionary.get(results[2])}, {dictionary.get(results[3])}, {dictionary.get(results[4])}, and {dictionary.get(results[5])}.'\n",
    "\n",
    "        # check to see if the person failed two months in a row to see if they are still eligble or must come in office.\n",
    "        if remote and last_fm:\n",
    "            reason = f'{reason}  They have one month to correct before coming back to the office.'\n",
    "            wah_df.loc[index, 'WAH Eligible'] = 'Yes'\n",
    "        elif remote and last_fm == False:\n",
    "            reason = f'{reason} This is their second month in a row. They must come into office.'\n",
    "            wah_df.loc[index, 'WAH Eligible'] = 'No'\n",
    "        else:\n",
    "            wah_df.loc[index, 'WAH Eligible'] = 'No'\n",
    "        wah_df.loc[index, 'Reason'] = reason\n",
    "else: \n",
    "    print('Current month completed in calculating')\n",
    "    print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wah_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a tilde to the beginning of schedules so that excel does not treat them as formulas\n",
    "wah_df['Days Worked'] = wah_df['Days Worked'].map(lambda x: \"`\" + x if x != None else x)\n",
    "print('Corrected schedule strings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering columns in order to output and sorting values\n",
    "new_column_order = ['Call Center',\n",
    "                    'Manager',\n",
    "                    'Supervisor',\n",
    "                    'Agent',\n",
    "                    'Title',\n",
    "                    'PSID',\n",
    "                    'Days Worked',\n",
    "                    'Start/Stop',\n",
    "                    'WorkPlace',\n",
    "                    'Remote',\n",
    "                    'Overall Rank',\n",
    "                    'Months_of_Data',\n",
    "                    'Works_Weekend',\n",
    "                    'Over 50',\n",
    "                    'No CA',\n",
    "                    'Overtime Met',\n",
    "                    'Shrink Pass', \n",
    "                    'Enough Data', \n",
    "                    'Pass Last FM',\n",
    "                    'Pass This Month',\n",
    "                    'WAH Eligible',\n",
    "                    'Reason']\n",
    "wah_df = wah_df.reindex(columns=new_column_order)\n",
    "wah_df = wah_df.sort_values(by=['Call Center', 'Manager', 'Supervisor', 'Agent'], ignore_index=True)\n",
    "print('Output columns corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writing to excel data sheet')\n",
    "wah_df.to_excel(data_path, index=False, sheet_name='WAH_Stutus')\n",
    "print('Excel sheet written')\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Opening Excel\")\n",
    "xlapp = win32com.client.Dispatch('Excel.Application')\n",
    "xlapp.Visible = True\n",
    "xlapp.DisplayAlerts = False\n",
    "wb = xlapp.Workbooks.Open(template_path)\n",
    "print('Excel has been opened')\n",
    "\n",
    "# refreshing all queries\n",
    "wb.RefreshAll()\n",
    "xlapp.CalculateUntilAsyncQueriesDone()\n",
    "print('Excel Data has been refreshed.')\n",
    "\n",
    "# deleting connections for output file\n",
    "for conn in wb.Queries:\n",
    "    conn.Delete()\n",
    "print('Connections have been removed.')\n",
    "\n",
    "# saving file in the determined folder and quitting excel\n",
    "wb.SaveAs(save_path)\n",
    "print(f'Workbook has been saved here: {save_path}')\n",
    "xlapp.DisplayAlerts = True\n",
    "wb.Close()\n",
    "xlapp.Quit()\n",
    "print('Excel has been closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy(save_path, server_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wah_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = wah_df.groupby(['Call Center', 'WorkPlace', 'WAH Eligible']).agg({\n",
    "    'WAH Eligible': 'count'\n",
    "}).rename(columns={'WAH Eligible': 'Count'}).reset_index().pivot(index=['WorkPlace', 'WAH Eligible'], columns='Call Center', values='Count')\n",
    "display_df['Total'] = display_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_cc = ['WorkPlace', 'WAH Eligible']\n",
    "cc_columns = [value for value in display_df.columns if value not in not_cc]\n",
    "\n",
    "for column in cc_columns:\n",
    "    hc_total = display_df[column].sum()\n",
    "    wah_total = display_df.loc[('WAH-PF', 'Yes'), column].sum() + display_df.loc[[('WIC-WORK_IN_CENTER', 'Yes')], column].sum()\n",
    "    wah_pct = wah_total / hc_total\n",
    "\n",
    "    display_df.loc[('Grand Total','Eligible Total'), column] = wah_total\n",
    "    display_df.loc[('Grand Total','WAH %'), column] = '{:.2%}'.format(wah_pct)\n",
    "\n",
    "index_list = [('WAH-PF', 'No'),\n",
    "              ('WAH-PF', 'Yes'),\n",
    "              ('WIC-WORK_IN_CENTER', 'No'),\n",
    "              ('WIC-WORK_IN_CENTER', 'Yes'),\n",
    "              ('Grand Total', 'Eligible Total')]\n",
    "\n",
    "for index in index_list:\n",
    "    display_df.loc[index] = display_df.loc[index].astype(int)\n",
    "    \n",
    "display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_df.columns.name = None\n",
    "# display_df.index.name = None\n",
    "email_display_df = display_df.style.set_table_styles(\n",
    "    [{'selector': '',\n",
    "      'props': 'border: 1px solid black; border-collapse: collapse; padding: 5px;'},\n",
    "      {'selector': 'td',\n",
    "     'props': 'border: 1px solid black; tborder-collapse: collapse; text-align: center;'},\n",
    "     {'selector': '.row_heading',\n",
    "     'props': 'text-align: left; font-weight: bold; border: 1px solid black; tborder-collapse: collapse;'},\n",
    "     {'selector': 'thead',\n",
    "     'props': 'background-color:#787878; color:white; border: 1px white; border-collapse: collapse;'},\n",
    "     {'selector': '.index_name',\n",
    "     'props': 'background-color:#787878; color:white; border: 1px white; border-collapse: collapse;'},\n",
    "     {'selector': '.blank',\n",
    "     'props': 'background-color:#787878; color:white; border: 1px white; border-collapse: collapse;'},\n",
    "     {'selector': 'table',\n",
    "     'props': 'border-collapse: collapse;'}]\n",
    ")\n",
    "\n",
    "table = email_display_df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring paths to local assets\n",
    "logo = os.path.join(src_folder, 'logo.png')\n",
    "vid_repair = os.path.join(src_folder, 'Leader_Logo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring html to build email\n",
    "header = '<td width=951 style=\"width:580.0pt;background:#787878;padding:0in 5.4pt 0in 5.4pt\";height:45.35pt\"><p><span style=\"color:white\"><img src=cid:vid_repair height=51></span></td>'\n",
    "explainer = \"<p>&nbsp;</p> <p class=MsoNormal><span style='color:black'>You can find the most recent snapshot for WAH Eligibility posted <a href=''><span style='font-size: 12.0pt'>here</span></a></span><span style='font-size:12.0pt;color:black'>.</span></p> <p class=MsoNormal><span style='color:black'>Below is a summary after the most recent data refresh.</span></p>\"\n",
    "conclusion = '<br><p><span style=\"color:black\">If you have any questions, please reach out <a href=\"mailto:\"><span style=\"font-size: 12.0pt\">here</span></a><span style=\"font-size:12.0pt;color:black\">.</span></span></p></br>'\n",
    "footer = f'<tr> <td width=951 valign=top style=\"width:713.4pt;background:#787878;padding: 0in 5.4pt 0in 5.4pt\"> <p style=\"margin-top:6.0pt;margin-right:0in; margin-bottom:6.0pt;margin-left:0in;text-align:center\"><b><span style=\"color:white\"><img border=0 width=168 height=53 src=cid:charter_logo></span></b></p> <p style=\"margin-top:6.0pt;margin-right:0in; margin-bottom:6.0pt;margin-left:0in;text-align:center\"><strong><span style=\"font-size:10.5pt;color:white\">For Internal Use Only</span></strong></p> <p style=\"margin-top:6.0pt;margin-right:0in; margin-bottom:6.0pt;margin-left:0in;text-align:center\"><span style=\"font-size:8.5pt;color:white\">This communication is the property of Charter Communications and is intended for internal use only. Distribution outside of the Company, in whole or part, is not permitted, except with Company permission in the course of your authorized duties. </span></p> <p style=\"margin-bottom:12.0pt;text-align:center\"><b><span style=\"color:white\">Video Reporting &amp; Analytics</span></b></p></td></tr>'\n",
    "body = f'<table border=0 cellspacing=0 cellpadding=0 style=\"border-collapse:collapse\"><tr>{header}</tr><tr>{explainer}</tr><tr align=\"center\"><br>{table}</br></tr>{conclusion}<p>&nbsp;</p>{footer}</table>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating email\n",
    "print('Launching Outlook')\n",
    "olMailItem = 0x0\n",
    "obj = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "# newMail = obj.CreateItemFromTemplate(template_path)\n",
    "newMail = obj.CreateItem(olMailItem)\n",
    "newMail.Subject = f\"LEADER: WAH Eligibility - {last_fiscal.strftime('%B %Y')}\"\n",
    "newMail.To = '' # Network Email Addresses\n",
    "newMail.CC = '' # Network Email Addresses\n",
    "vid_repair_logo = newMail.Attachments.Add(vid_repair)\n",
    "vid_repair_logo.PropertyAccessor.SetProperty(\"http://schemas.microsoft.com/mapi/proptag/0x3712001F\", \"vid_repair\")\n",
    "charter_logo = newMail.Attachments.Add(logo)\n",
    "charter_logo.PropertyAccessor.SetProperty(\"http://schemas.microsoft.com/mapi/proptag/0x3712001F\", \"charter_logo\")\n",
    "newMail.HTMLBody = body\n",
    "newMail.Display()\n",
    "# newMail.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
